{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMibDHvpdW915O8xZfLD2Os",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aditya-sharma112245/student-intro-evaluator/blob/main/project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install streamlit -q\n",
        "!pip install language-tool-python -q\n",
        "!pip install nltk -q\n",
        "!pip install vaderSentiment -q\n",
        "!pip install sentence-transformers -q\n",
        "!pip install pyngrok -q\n",
        "\n",
        "# Download NLTK resources\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "# Configure ngrok with your token\n",
        "!ngrok authtoken 35qAefZ0oi7d3cwHUMpb9bkzXGh_37V6hoDx1UZSVdtr5Lm1v\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8oHvxwfhjIk1",
        "outputId": "37752021-7b9c-4967-d069-97a8ddba4ee0"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import language_tool_python\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk import FreqDist\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import re\n",
        "\n",
        "# Initialize models\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "tool = language_tool_python.LanguageTool('en-US')\n",
        "\n",
        "# Rubric keywords\n",
        "must_have_keywords = {\n",
        "    \"name\": r\"\\b(?:my name is|i am|myself)\\s+([A-Z][a-z]+)\",\n",
        "    \"age\": r\"\\b(\\d{1,2})\\s+years?\\s+old\\b\",\n",
        "    \"class\": r\"\\bclass\\s+\\d+[a-zA-Z]*\\b\",\n",
        "    \"school\": r\"\\b(school|institute|college)\\b\",\n",
        "    \"family\": r\"\\b(family|father|mother|brother|sister)\\b\",\n",
        "    \"hobbies\": r\"\\b(play|reading|sports|hobby|interest)\\b\",\n",
        "    \"goal\": r\"\\b(goal|dream|ambition)\\b\",\n",
        "    \"fun_fact\": r\"\\b(fun fact|something unique|interesting thing)\\b\"\n",
        "}\n",
        "\n",
        "good_to_have_keywords = {\n",
        "    \"origin\": r\"\\bfrom\\b\",\n",
        "    \"strength\": r\"\\b(strength|achievement|skill)\\b\"\n",
        "}\n",
        "\n",
        "filler_words = [\"um\", \"uh\", \"like\", \"you know\", \"so\", \"actually\", \"basically\",\n",
        "                \"right\", \"i mean\", \"well\", \"kinda\", \"sort of\", \"okay\", \"hmm\", \"ah\"]\n",
        "\n",
        "def extract_keywords(text):\n",
        "    found = []\n",
        "    for k, pattern in must_have_keywords.items():\n",
        "        if re.search(pattern, text.lower()):\n",
        "            found.append(k)\n",
        "    for k, pattern in good_to_have_keywords.items():\n",
        "        if re.search(pattern, text.lower()):\n",
        "            found.append(k)\n",
        "    return found\n",
        "\n",
        "def evaluate_transcript(text, duration_sec=52):\n",
        "    words = word_tokenize(text)\n",
        "    word_count = len(words)\n",
        "    sentence_count = len(sent_tokenize(text))\n",
        "\n",
        "    # --- Content & Structure ---\n",
        "    # Salutation\n",
        "    salutations = [\"hi\", \"hello\", \"good morning\", \"good afternoon\", \"good evening\", \"good day\", \"hello everyone\", \"i am excited\", \"feeling great\"]\n",
        "    salutation_score = 0\n",
        "    for sal in salutations:\n",
        "        if sal in text.lower():\n",
        "            if sal in [\"i am excited\", \"feeling great\"]:\n",
        "                salutation_score = 5\n",
        "            elif sal in [\"good morning\",\"good afternoon\",\"good evening\",\"good day\",\"hello everyone\"]:\n",
        "                salutation_score = 4\n",
        "            else:\n",
        "                salutation_score = 2\n",
        "            break\n",
        "\n",
        "    # Keyword presence\n",
        "    found_keywords = extract_keywords(text)\n",
        "    must_score = sum(4 for k in must_have_keywords if k in found_keywords)\n",
        "    good_score = sum(2 for k in good_to_have_keywords if k in found_keywords)\n",
        "    keyword_score = min(30, must_score + good_score)\n",
        "\n",
        "    # Flow check: basic order: Salutation → Basic Details → Additional → Closing\n",
        "    flow_score = 0\n",
        "    text_lower = text.lower()\n",
        "    if any(s in text_lower for s in salutations):\n",
        "        basic_details_order = [\"name\", \"age\", \"class\", \"school\"]\n",
        "        if all(bd in found_keywords for bd in basic_details_order):\n",
        "            flow_score = 5\n",
        "\n",
        "    content_structure_score = salutation_score + keyword_score + flow_score  # max 40\n",
        "\n",
        "    # --- Speech Rate ---\n",
        "    wpm = word_count / (duration_sec/60)\n",
        "    if 111 <= wpm <= 140:\n",
        "        speech_rate_score = 10\n",
        "    elif 141 <= wpm <= 160 or 81 <= wpm <= 110:\n",
        "        speech_rate_score = 6\n",
        "    elif wpm > 160:\n",
        "        speech_rate_score = 2\n",
        "    else:\n",
        "        speech_rate_score = 2  # too slow\n",
        "\n",
        "    # --- Language & Grammar ---\n",
        "    matches = tool.check(text)\n",
        "    errors_per_100 = len(matches)/max(word_count/100,1)\n",
        "    grammar_score = max(2, min(10, int((1 - min(errors_per_100/10, 1))*10)))\n",
        "\n",
        "    ttr = len(set(words))/word_count\n",
        "    if ttr >= 0.9:\n",
        "        vocab_score = 10\n",
        "    elif ttr >=0.7:\n",
        "        vocab_score = 8\n",
        "    elif ttr >=0.5:\n",
        "        vocab_score = 6\n",
        "    elif ttr >=0.3:\n",
        "        vocab_score = 4\n",
        "    else:\n",
        "        vocab_score = 2\n",
        "\n",
        "    # --- Clarity (Filler words) ---\n",
        "    filler_count = sum(words.count(w) for w in filler_words)\n",
        "    filler_rate = (filler_count/word_count)*100\n",
        "    if filler_rate <=3:\n",
        "        filler_score = 15\n",
        "    elif filler_rate <=6:\n",
        "        filler_score = 12\n",
        "    elif filler_rate <=9:\n",
        "        filler_score = 9\n",
        "    elif filler_rate <=12:\n",
        "        filler_score = 6\n",
        "    else:\n",
        "        filler_score = 3\n",
        "\n",
        "    # --- Engagement (Sentiment) ---\n",
        "    sentiment = analyzer.polarity_scores(text)\n",
        "    pos_prob = sentiment['pos']\n",
        "    if pos_prob >= 0.9:\n",
        "        sentiment_score = 15\n",
        "    elif pos_prob >=0.7:\n",
        "        sentiment_score = 12\n",
        "    elif pos_prob >=0.5:\n",
        "        sentiment_score = 9\n",
        "    elif pos_prob >=0.3:\n",
        "        sentiment_score = 6\n",
        "    else:\n",
        "        sentiment_score = 3\n",
        "\n",
        "    # --- Semantic similarity (bonus) ---\n",
        "    rubric_text = \"Student introduction should include greeting, name, age, class, school, family details, hobbies, interests, goals, and unique/fun facts.\"\n",
        "    embedding_sim = util.cos_sim(model.encode(text), model.encode(rubric_text)).item()\n",
        "    semantic_score = min(10, max(0, int(embedding_sim*10)))\n",
        "\n",
        "    # --- Total score ---\n",
        "    total_score = content_structure_score + speech_rate_score + grammar_score + vocab_score + filler_score + sentiment_score + semantic_score\n",
        "    total_score = min(100, total_score)\n",
        "\n",
        "    # Feedback\n",
        "    feedback = {\n",
        "        \"Salutation Score\": salutation_score,\n",
        "        \"Keyword Score\": keyword_score,\n",
        "        \"Flow Score\": flow_score,\n",
        "        \"Speech Rate (WPM)\": round(wpm,2),\n",
        "        \"Speech Rate Score\": speech_rate_score,\n",
        "        \"Grammar Errors\": len(matches),\n",
        "        \"Grammar Score\": grammar_score,\n",
        "        \"Vocabulary TTR\": round(ttr,2),\n",
        "        \"Vocabulary Score\": vocab_score,\n",
        "        \"Filler Words Count\": filler_count,\n",
        "        \"Filler Score\": filler_score,\n",
        "        \"Positive Sentiment Probability\": round(pos_prob,2),\n",
        "        \"Sentiment Score\": sentiment_score,\n",
        "        \"Semantic Similarity\": round(embedding_sim,2),\n",
        "        \"Semantic Score\": semantic_score,\n",
        "        \"Keywords Found\": found_keywords\n",
        "    }\n",
        "\n",
        "    return total_score, feedback\n",
        "\n",
        "# --- Streamlit UI ---\n",
        "st.title(\"Student Introduction Evaluator\")\n",
        "transcript = st.text_area(\"Paste Transcript Here:\")\n",
        "\n",
        "duration_sec = st.number_input(\"Duration of speech in seconds:\", min_value=1, value=52)\n",
        "\n",
        "if st.button(\"Score\"):\n",
        "    if transcript.strip() == \"\":\n",
        "        st.warning(\"Please enter a transcript first.\")\n",
        "    else:\n",
        "        score, feedback = evaluate_transcript(transcript, duration_sec)\n",
        "        st.subheader(f\"Overall Score: {score}/100\")\n",
        "        st.write(\"### Detailed Feedback:\")\n",
        "        st.json(feedback)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dOvKLqojJBO",
        "outputId": "521e8c9e-ac41-470e-e06a-f2db5d02875e"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Kill all existing tunnels\n",
        "ngrok.kill()\n"
      ],
      "metadata": {
        "id": "gDlY47WfjYN7"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "public_url = ngrok.connect(8501)\n",
        "print(\"Your Streamlit app is live at:\", public_url)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Dj3l4PXjbgT",
        "outputId": "7075fbfc-6684-4580-9ead-3e2ce87cb8b7"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your Streamlit app is live at: NgrokTunnel: \"https://92bcc7ca6775.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2g9j7eD0ji3w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}